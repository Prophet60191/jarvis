RAG Memory System Technical Details

The RAG (Retrieval-Augmented Generation) system in Jarvis provides sophisticated memory capabilities through ChromaDB vector storage.

Technical Implementation:
- Vector Database: ChromaDB for persistent storage
- Embeddings: Ollama embeddings for semantic understanding
- Text Splitting: Recursive character text splitter with 1000 character chunks
- Search: Semantic similarity search with configurable k value

Document Processing:
Supported file formats:
- PDF files (.pdf) - Using PyPDFLoader
- Text files (.txt) - Using TextLoader  
- Word documents (.doc, .docx) - Using UnstructuredWordDocumentLoader

The system automatically processes documents by:
1. Loading content using appropriate loaders
2. Splitting into manageable chunks with overlap
3. Generating embeddings for semantic search
4. Storing in ChromaDB with source metadata

Memory Types:
1. Conversational Memory: Facts explicitly stored by user commands
2. Document Memory: Knowledge extracted from ingested documents
3. Unified Search: Single search interface across both memory types

Configuration:
- chunk_size: 1000 characters per chunk
- chunk_overlap: 150 characters overlap between chunks
- search_k: 5 results returned per search
- collection_name: jarvis_memory
- vector_store_path: data/chroma_db
- documents_path: data/documents

The system provides seamless integration where users can ask questions that draw from both conversational memories and document knowledge without needing to specify the source.
